{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import operators as op\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "# import lightgbm as lgbm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import model_from_json\n",
    "from sklearn import linear_model\n",
    "# For neural network\n",
    "from tensorflow.keras.models import Sequential, Model, model_from_json\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, LeakyReLU, BatchNormalization, PReLU, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers, optimizers, losses\n",
    "##### to limit number of cores used by TensorFlow ####\n",
    "from keras import backend as K\n",
    "import tensorflow \n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNNModel3(input_dim=9):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(26, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile1(model):\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 26)                234       \n",
      "=================================================================\n",
      "Total params: 1,538\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = getNNModel3(26+4)\n",
    "compile1(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeWord(word, guesses):\n",
    "    encoding = []\n",
    "    for c in word:\n",
    "        ci = ord(c)-ord('a')\n",
    "        if(guesses[ci]==0):\n",
    "            encoding += [27]\n",
    "        else:\n",
    "            encoding += [ord(c)-ord('a')+1]\n",
    "    return np.concatenate([np.array(encoding), guesses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27., 27., 27., 27., 27.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodeWord(\"asdas\",np.zeros(26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "with open('words_250000_train.txt','r') as f:\n",
    "    for l in f.readlines():\n",
    "        words += [l[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_by_length = {}\n",
    "for w in words:\n",
    "    if(len(w) in words_by_length.keys()):\n",
    "        words_by_length[len(w)] += [w]\n",
    "    else:\n",
    "        words_by_length[len(w)] = [w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 6, 4, 5, 8, 7, 10, 9, 11, 12, 13, 15, 14, 20, 17, 16, 2, 21, 18, 19, 25, 22, 1, 23, 29, 24, 28, 27])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_by_length.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidGuesses(word, guesses):\n",
    "    valids = np.zeros(26)\n",
    "    for c in word:\n",
    "        ci = ord(c) - ord('a')\n",
    "        if(guesses[ci]==0):\n",
    "            valids[ci]+=1\n",
    "    return valids/(sum(valids)+1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25 , 0.125, 0.125, 0.125, 0.125, 0.125, 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "       0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getValidGuesses(\"aabcdef\",np.zeros(26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_guesses = np.zeros(26)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n",
      "4\n",
      "5\n",
      "8\n",
      "7\n",
      "10\n",
      "9\n",
      "11\n",
      "12\n",
      "13\n",
      "15\n",
      "14\n",
      "20\n",
      "17\n",
      "16\n",
      "2\n",
      "21\n",
      "18\n",
      "19\n",
      "25\n",
      "22\n",
      "1\n",
      "23\n",
      "29\n",
      "24\n",
      "28\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "models_all = {}\n",
    "for k in words_by_length.keys():\n",
    "    print(k)\n",
    "    models_all[k] = getNNModel3(k+26)\n",
    "    compile1(models_all[k])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_240 (Dense)            (None, 16)                512       \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 26)                234       \n",
      "=================================================================\n",
      "Total params: 1,554\n",
      "Trainable params: 1,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models_all[5].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15060"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "       0.        , 0.        , 0.33333333, 0.        , 0.33333333,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret '3' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-118543318af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret '3' as a data type"
     ]
    }
   ],
   "source": [
    "np.zeros(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_all[5] = getNNModel3(31)\n",
    "compile1(models_all[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######single word at a time, single fit at a time#####\n",
    "# word_length = 5\n",
    "# epochs = 5\n",
    "# for e in range(epochs):\n",
    "#         print('epoch: ',e)\n",
    "#         wins = 0\n",
    "#         losses = 0\n",
    "#         prev_start_index = 0\n",
    "#         block_size = 10\n",
    "        \n",
    "#         for wi,word in enumerate(words_by_length[word_length][prev_start_index:prev_start_index+block_size]):\n",
    "# #             if(wi%10000==0):\n",
    "# # #                 clear_output(,wait=True)\n",
    "# # #                 display('Iteration '+str(i)+' Score: '+str(uniform(0, 1)))\n",
    "# #                 print(wi)\n",
    "# #             print(word)\n",
    "#             tries_left = np.zeros(block_size)+6\n",
    "#             guesses = np.zeros((block_size,26))\n",
    "#             valid_guesses = np.array([getValidGuesses(word,guesses)])\n",
    "#             while(tries_left!=0 and sum(valid_guesses)!=0):\n",
    "#                 encoded = encodeWord(word, guesses).reshape(1,-1)\n",
    "#                 predicted = models_all[word_length].predict([encoded])\n",
    "\n",
    "#                 models_all[word_length].fit(encoded,valid_guesses.reshape(1,-1), verbose=False)\n",
    "\n",
    "#     #             print(guesses)\n",
    "\n",
    "#                 predicted[0][(guesses!=0)] = 0\n",
    "#                 new_guess = np.argmax(predicted)\n",
    "\n",
    "#                 guesses[new_guess] = 1\n",
    "\n",
    "#                 if(valid_guesses[new_guess]>0):\n",
    "#                     valid_guesses = getValidGuesses(word, guesses)\n",
    "#                 else:\n",
    "#                     tries_left-=1\n",
    "\n",
    "#             if(tries_left==0):\n",
    "#                 losses += 1\n",
    "# #                 print('valid guesses left:',np.where(valid_guesses!=0),[chr(ord('a')+i) for i in np.where(valid_guesses!=0)[0]])\n",
    "# #                 print('tries_left: ',tries_left)\n",
    "#             else:\n",
    "#                 wins += 1\n",
    "# #                 print('tries_left: ',tries_left)\n",
    "#         prev_start_index += block_size\n",
    "#         print('wins: ',wins,\"and losses:\",losses)\n",
    "# #                 print('guessed:',chr(ord('a')+new_guess)+\" and tried_left:\",tries_left)\n",
    "# #                 print('valid guesses left:',[chr(ord('a')+i) for (i,x) in enumerate(valid_guesses)  if x>0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nicol', 'fulup', 'donia', 'kaine', 'genys', 'arcos', 'gapes',\n",
       "       'goudy', 'nobby', 'gough', 'creon', 'givin', 'deter', 'claye',\n",
       "       'boosy', 'decem', 'bakra', 'azide', 'pamir', 'toled', 'tulip',\n",
       "       'troot', 'segni', 'mosts', 'astto', 'neeps', 'sluit', 'mazda',\n",
       "       'yanky', 'ranid', 'hexad', 'iloko', 'soncy', 'unman', 'kelcy',\n",
       "       'oshee', 'paint', 'eaten', 'idmon', 'plott', 'schug', 'ociaa',\n",
       "       'grise', 'estop', 'oakie', 'bombo', 'boogy', 'redip', 'adron',\n",
       "       'ovapa', 'masai', 'venez', 'polio', 'tepal', 'orvas', 'acast',\n",
       "       'sugat', 'gwari', 'wodgy', 'issue', 'abram', 'tofus', 'feune',\n",
       "       'ossie', 'email', 'algin', 'abohm', 'winny', 'charm', 'muons',\n",
       "       'brays', 'balpa', 'shojo', 'huaco', 'lotis', 'pfalz', 'sobor',\n",
       "       'grike', 'galli', 'rebag', 'cappy', 'roana', 'ruffs', 'ejido',\n",
       "       'taces', 'ligon', 'jumpy', 'musil', 'chirm', 'biron', 'giing',\n",
       "       'troff', 'orosi', 'needy', 'ohare', 'kaphs', 'kalle', 'oshee',\n",
       "       'skint', 'zawde', 'crsab', 'aymer', 'scart', 'radly', 'punch',\n",
       "       'slide', 'skite', 'smell', 'urbas', 'sworn', 'assen', 'gladi',\n",
       "       'resit', 'logis', 'baldr', 'lamby', 'seems', 'subah', 'vases',\n",
       "       'tioga', 'cluck', 'bakie', 'waldo', 'agamy', 'roald', 'nafis',\n",
       "       'abner', 'cosed', 'bosun', 'bylaw', 'arawn', 'bessy', 'wroke',\n",
       "       'lagen', 'astto', 'fumer', 'hagio', 'vughs', 'faxun', 'davis',\n",
       "       'coopt', 'saver', 'cocka', 'speen', 'flinn', 'afire', 'moron',\n",
       "       'caste', 'flask', 'topos', 'resit', 'macri', 'codel', 'aldim',\n",
       "       'eriha', 'arkie', 'yajna', 'gooff', 'cheir', 'lanse', 'oolly',\n",
       "       'ankhs', 'wraps', 'zurek', 'menlo', 'palea', 'tuple', 'kurth',\n",
       "       'brest', 'pridy', 'hauls', 'karly', 'heida', 'malin', 'kwasi',\n",
       "       'triol', 'nefas', 'cujam', 'oidal', 'kenzi', 'sophs', 'bandy',\n",
       "       'yssel', 'disna', 'knurs', 'cozad', 'dingo', 'tchwi', 'ilana',\n",
       "       'frill', 'heils', 'dabby', 'tabbi', 'betel', 'turfs', 'datum',\n",
       "       'heloe', 'merla', 'odilo', 'taver', 'wowed', 'floss', 'unlap',\n",
       "       'hodad', 'wiota', 'kokia', 'pesek', 'peans', 'bedel', 'usbeg',\n",
       "       'coccy', 'morra', 'growl', 'heise', 'wyles', 'kafre', 'mousy',\n",
       "       'triad', 'lenee', 'itala', 'acast', 'kioga', 'dodds', 'voust',\n",
       "       'kalin', 'kaile', 'jugal', 'fumid', 'grist', 'creen', 'fouqu',\n",
       "       'imler', 'rhona', 'leaky', 'puses', 'copal', 'janel', 'fidia',\n",
       "       'edson', 'addle', 'shift', 'iortn', 'braze', 'poter', 'toldo',\n",
       "       'juxon', 'fundi', 'dight', 'befan', 'early', 'milos', 'write',\n",
       "       'porte', 'jaban', 'neons', 'lilla', 'roost', 'bebat', 'creil',\n",
       "       'rumal', 'jerid', 'kadis', 'iceni', 'nucla', 'gives', 'scran',\n",
       "       'duong', 'palus', 'rogan', 'yokum', 'adage', 'newel', 'tabes',\n",
       "       'gipps', 'heize', 'dotal', 'prodd', 'halas', 'donni', 'tufas',\n",
       "       'deign', 'spear', 'kalle', 'loges', 'sards', 'kiddo', 'woody',\n",
       "       'rouge', 'spout', 'shawy', 'yourt', 'rehoe', 'wirth', 'sheik',\n",
       "       'mahan', 'doley', 'helsa', 'whorl', 'haded', 'jubes', 'oopod',\n",
       "       'wrote', 'twere', 'klans', 'blenk', 'filix', 'alana', 'dedie',\n",
       "       'jolty', 'brana', 'agave', 'kinch', 'chald', 'karou', 'gogos',\n",
       "       'idyls', 'saimy', 'hache', 'wasps', 'moner', 'alejo', 'henge',\n",
       "       'arose', 'lalls', 'oland', 'freck', 'sidia', 'joash', 'wasnt',\n",
       "       'randy', 'bantu', 'deryl', 'amply', 'abdel', 'tween', 'idona',\n",
       "       'kukui', 'hound', 'humpy', 'shram', 'fuffy', 'lunet', 'harli',\n",
       "       'binit', 'commo', 'msink', 'monza', 'steen', 'uncow', 'texas',\n",
       "       'shuzo', 'oaken', 'minoa', 'mafic', 'gusla', 'cabaa', 'hoppe',\n",
       "       'daggy', 'britt', 'phono', 'amati', 'heben', 'ester', 'carap',\n",
       "       'festy', 'knarl', 'annwn', 'ditas', 'zetas', 'brush', 'locks',\n",
       "       'roofs', 'gladi', 'uboot', 'shogs', 'coals', 'dangs', 'cough',\n",
       "       'purim', 'wuppe', 'overs', 'spire', 'frike', 'stuss', 'fundy',\n",
       "       'lindy', 'beria', 'naira', 'outen', 'girth', 'randy', 'ozone',\n",
       "       'zante', 'donts', 'glaze', 'scatt', 'lehet', 'mafic', 'hollo',\n",
       "       'wanle', 'ivory', 'spalt', 'codex', 'banes', 'eucre', 'gighe',\n",
       "       'lasty', 'lurer', 'awacs', 'coign', 'wuwei', 'buddh', 'dawts',\n",
       "       'ready', 'macey', 'hoers', 'salty', 'aptly', 'alcot', 'emlen',\n",
       "       'ictus', 'aceae', 'daily', 'doall', 'dakar', 'bazar', 'teles',\n",
       "       'fauch', 'ebbet', 'redds', 'ashen', 'dells', 'bilek', 'ureic',\n",
       "       'cisco', 'fancy', 'druxy', 'kerek', 'csiro', 'baubo', 'nasua',\n",
       "       'corol', 'softs', 'ahvaz', 'gippy', 'groma', 'liney', 'bogey',\n",
       "       'colen', 'eloah', 'damns', 'ungag', 'mytho', 'enent', 'blurb',\n",
       "       'darst', 'macap', 'cloys', 'tabel', 'vapid', 'recip', 'mavra',\n",
       "       'bille', 'mysis', 'swann', 'cisne', 'yores', 'tunka', 'iatro',\n",
       "       'netti', 'upway', 'jbeil', 'deric', 'chirm', 'lepas', 'rebeg',\n",
       "       'lopez', 'bsdes', 'fears', 'arach', 'okrug', 'ahong', 'sahib',\n",
       "       'pests', 'viced', 'pence', 'torch', 'alapa', 'hsien', 'zelde',\n",
       "       'torry', 'rompy', 'naker', 'hutre', 'poori', 'gryde', 'ismay',\n",
       "       'bunow', 'erika', 'quaff', 'creed', 'glave', 'plate', 'chark',\n",
       "       'arene', 'haney', 'shuln', 'nunes', 'tulia', 'laval', 'ardys',\n",
       "       'apios', 'cobia', 'neoga', 'kwela', 'udale', 'infra', 'oboes',\n",
       "       'dream', 'agist', 'hoffa', 'while', 'zimme', 'leach', 'blare',\n",
       "       'bongs', 'strow', 'klemm', 'sible', 'maana', 'garni', 'seram',\n",
       "       'hexer', 'mulse', 'eosin', 'sligo', 'mazie', 'oncin', 'mokum',\n",
       "       'halfa', 'swell', 'ivies', 'caker', 'proud', 'reine', 'joash',\n",
       "       'homeo', 'cosby', 'guiac', 'kynan', 'singe', 'bretz', 'kroon',\n",
       "       'soler', 'ranis', 'dvina', 'ludes', 'orian', 'valva', 'kaska',\n",
       "       'codes', 'halla', 'torto', 'hopak', 'furls', 'takyr', 'taroc',\n",
       "       'homer', 'gusto', 'roose', 'archd', 'wurtz', 'edman', 'beady',\n",
       "       'quark', 'ovoid', 'lanse', 'mayer', 'astri', 'byler', 'mitzl',\n",
       "       'biffy', 'belve', 'whalp', 'japan', 'labaw', 'chara', 'ngoma',\n",
       "       'brahm', 'singe', 'fists', 'howdy', 'guyon', 'baals', 'habbe',\n",
       "       'narra', 'ioyal', 'redug', 'diced', 'gloea', 'aklog', 'pauli',\n",
       "       'butsu', 'catty', 'crewe', 'bloop', 'frett', 'squab', 'edtcc',\n",
       "       'bgirl', 'dexes', 'balei', 'limbi', 'ounce', 'perea', 'druse',\n",
       "       'usbek', 'chria', 'amias', 'issie', 'ascap', 'brahe', 'bitto',\n",
       "       'tucum', 'horan', 'icker', 'dobra', 'iambs', 'zoeae', 'yuzik',\n",
       "       'bungy', 'lodie', 'addie', 'uvala', 'rodez', 'banff', 'gynec',\n",
       "       'rinch', 'kyano', 'kobus', 'shuzo', 'stale', 'sicel', 'giana',\n",
       "       'jumma', 'janot', 'kenny', 'osset', 'earom', 'filum', 'roget',\n",
       "       'taxir', 'itnez', 'aleph', 'lemay', 'kubis', 'xylol', 'fabio',\n",
       "       'sairy', 'samaj', 'alice', 'tease', 'gatun', 'comox', 'aulae',\n",
       "       'zirai', 'wopsy', 'slaby', 'bluff', 'fosie', 'sises', 'gring',\n",
       "       'tuant', 'nudie', 'tyste', 'buraq', 'feuar', 'dogly', 'katha',\n",
       "       'coorg', 'wrack', 'ifere', 'biter', 'wheys', 'verel', 'rebeg',\n",
       "       'atria', 'lumbo', 'knick', 'rabid', 'buote', 'boyle', 'swang',\n",
       "       'ralph', 'vigia', 'banco', 'ediva', 'hadnt', 'donas', 'zings',\n",
       "       'weste', 'carne', 'apeek', 'progs', 'rebag', 'segos', 'blick',\n",
       "       'hurri', 'thida', 'alter', 'usbeg', 'shrab', 'water', 'ponga',\n",
       "       'viced', 'oruro', 'stied', 'orals', 'linda', 'moray', 'chivw',\n",
       "       'euton', 'oxman', 'alike', 'rehab', 'limbi', 'jamey', 'chirm',\n",
       "       'arach', 'zelos', 'edwin', 'cyath', 'doest', 'hanan', 'sarus',\n",
       "       'whipt', 'asahi', 'redia', 'saris', 'drugs', 'pavan', 'gueux',\n",
       "       'thane', 'redby', 'redig', 'tiler', 'bidri', 'elger', 'feels',\n",
       "       'veuve', 'cogie', 'unsin', 'suras', 'dafla', 'halke', 'klans',\n",
       "       'scant', 'feedy', 'behew', 'gored', 'lacet', 'blebs', 'razor',\n",
       "       'triol', 'oaken', 'fagin', 'fitch', 'voust', 'adala', 'aghan',\n",
       "       'notch', 'engen', 'sabah', 'amase', 'yurok', 'casel', 'feted',\n",
       "       'toise', 'wheki', 'lazio', 'fugal', 'ating', 'rerun', 'routs',\n",
       "       'loose', 'yauco', 'jacey', 'savoy', 'palew', 'sluff', 'calie',\n",
       "       'fourb', 'idona', 'gause', 'ative', 'rondo', 'catso', 'nills',\n",
       "       'ahsan', 'muset', 'uncle', 'maewo', 'knarl', 'frits', 'olton',\n",
       "       'jessa', 'lovie', 'wyeth', 'mayed', 'sorty', 'puget', 'altha',\n",
       "       'fotui', 'flurr', 'vinta', 'pinch', 'duals', 'gader', 'roehm',\n",
       "       'denys', 'situs', 'cliff', 'aviso', 'rhona', 'fuzes', 'bsadv',\n",
       "       'filum', 'megan', 'trant', 'pores', 'diter', 'color', 'tiple',\n",
       "       'uwton', 'hufuf', 'lowis', 'filmy', 'roger', 'peetz', 'brags',\n",
       "       'thorn', 'recco', 'coign', 'tavel', 'opine', 'effet', 'write',\n",
       "       'durst', 'junet', 'suine', 'nunky', 'jagir', 'gadge', 'monax',\n",
       "       'kokia', 'zoned', 'wilde', 'tabac', 'ebeye', 'gater', 'musci',\n",
       "       'cdoba', 'tahar', 'taxin', 'baure', 'chrys', 'chymo', 'dasha',\n",
       "       'luite', 'crany', 'crane', 'dauke', 'dorse', 'knipe', 'becut',\n",
       "       'wadai', 'peggi', 'picry', 'scobs', 'gomez', 'lincs', 'farls',\n",
       "       'aside', 'kudva', 'heals', 'cecca', 'groop', 'pulis', 'hoppe',\n",
       "       'koloa', 'brush', 'looby', 'swire', 'akaba', 'ladin', 'sheik',\n",
       "       'gurge', 'kimon', 'maynt', 'pubis', 'ploys', 'omari', 'rompy',\n",
       "       'ewers', 'orvas', 'algic', 'mudee', 'scaup', 'tronc', 'hails',\n",
       "       'binna', 'eloah', 'thurt', 'hodad', 'mexia', 'gotra', 'sargo',\n",
       "       'hardi', 'disks', 'saple', 'greet', 'bange', 'bidet', 'mince',\n",
       "       'ninon', 'dealt', 'aniak', 'xhigh', 'bowet', 'deets', 'anomy',\n",
       "       'topos', 'roils', 'dower', 'retch', 'padua', 'lubes', 'rynds',\n",
       "       'prato', 'pilin', 'zingg', 'ornas', 'mesic', 'vaduz', 'eying',\n",
       "       'laing', 'mahri', 'badju', 'alane', 'cicer', 'rucky', 'ozone',\n",
       "       'smook', 'salmo', 'harry', 'erose', 'archi', 'ander', 'drusy',\n",
       "       'punct', 'boucl', 'ethno', 'sumba', 'gilts', 'plote', 'dflat',\n",
       "       'duras', 'bluma', 'matty', 'toker', 'cheme', 'canby', 'arter',\n",
       "       'farny', 'polio', 'eppes', 'bunga', 'milos', 'reasy', 'music',\n",
       "       'kukri', 'weesh', 'loops', 'spaer', 'ecart', 'snast', 'boers',\n",
       "       'voust', 'scuds', 'ajuga', 'vinea', 'blate', 'topia', 'yaboo',\n",
       "       'istle', 'fiord', 'purga', 'embry', 'mowie', 'rondo'], dtype='<U5')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(words_by_length[word_length][:100000],1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "traning_set5 = \n",
    "test_set5 = [x for x in words_by_length[5] if x not in traning_set5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_lengthe:  1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_316_input to have shape (27,) but got array with shape (31,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-370a63e71411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mvalid_guesses_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalid_guesses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguesses\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mnew_guess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 705\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    706\u001b[0m     return predict_loop(\n\u001b[1;32m    707\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2334\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2335\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2361\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils_v1.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    538\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    541\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_316_input to have shape (27,) but got array with shape (31,)"
     ]
    }
   ],
   "source": [
    "#######single word at a time, multiple fit at a time#####\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    for word_length in list(sorted(words_by_length.keys()))[:4]:\n",
    "\n",
    "            training_set = np.random.choice(words_by_length[word_length],int(0.8*len(words_by_length[word_length])))\n",
    "            test_set = [x for x in words_by_length[word_length] if x not in training_set]\n",
    "    \n",
    "            print('word_lengthe: ',word_length)\n",
    "            wins = 0\n",
    "            losses = 0\n",
    "            gc.collect()\n",
    "            for wi,word in enumerate(np.random.choice(traning_set5,10)):\n",
    "#                 if(wi%100==0):\n",
    "#                     print(wi)\n",
    "                tries_left = 6\n",
    "                guesses = np.zeros(26)\n",
    "                valid_guesses = getValidGuesses(word,guesses)\n",
    "\n",
    "                encoded_all = []\n",
    "                valid_guesses_all = []\n",
    "\n",
    "                while(tries_left!=0 and sum(valid_guesses)!=0):\n",
    "                    encoded = encodeWord(word, guesses)\n",
    "\n",
    "                    encoded_all += [encoded]\n",
    "                    valid_guesses_all += [valid_guesses]\n",
    "\n",
    "                    predicted = models_all[word_length].predict([encoded.reshape(1,-1)])\n",
    "                    predicted[0][(guesses!=0)] = 0\n",
    "                    new_guess = np.argmax(predicted)\n",
    "\n",
    "                    guesses[new_guess] = 1\n",
    "\n",
    "                    if(valid_guesses[new_guess]>0):\n",
    "                        valid_guesses = getValidGuesses(word, guesses)\n",
    "                    else:\n",
    "                        tries_left-=1\n",
    "\n",
    "                encoded_all += [encodeWord(word, guesses)]\n",
    "                valid_guesses_all += [valid_guesses]\n",
    "\n",
    "\n",
    "\n",
    "                encoded_all = np.array(encoded_all)\n",
    "                valid_guesses_all = np.array(valid_guesses_all)\n",
    "\n",
    "\n",
    "    #             print(encoded_all.shape, valid_guesses_all.shape)\n",
    "\n",
    "                models_all[word_length].fit(encoded_all,valid_guesses_all, verbose=False)        \n",
    "\n",
    "                if(tries_left==0):\n",
    "                    losses += 1\n",
    "    #                 print('valid guesses left:',np.where(valid_guesses!=0),[chr(ord('a')+i) for i in np.where(valid_guesses!=0)[0]])\n",
    "    #                 print('tries_left: ',tries_left)\n",
    "                else:\n",
    "                    wins += 1\n",
    "    #                 print('tries_left: ',tries_left)\n",
    "            prev_start_index += block_size\n",
    "            print('wins: ',wins,\"and losses:\",losses)\n",
    "\n",
    "        \n",
    "#                 print('guessed:',chr(ord('a')+new_guess)+\" and tried_left:\",tries_left)\n",
    "#                 print('valid guesses left:',[chr(ord('a')+i) for (i,x) in enumerate(valid_guesses)  if x>0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-e04e03da5b13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mmodels_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_guesses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#             print(guesses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m       \u001b[0;31m# Collecting and resetting metrics has non-zero cost and will needlessly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m       \u001b[0;31m# slow down model.predict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_training_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[0;31m# Reset metrics on all the distributed (cloned) models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3729\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3730\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3731\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1369\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1360\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1451\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#######multiple word at a time#####\n",
    "# word_length = 5\n",
    "# epochs = 5\n",
    "# for e in range(epochs):\n",
    "#         print('epoch: ',e)\n",
    "#         wins = 0\n",
    "#         losses = 0\n",
    "#         prev_start_index = 0\n",
    "#         block_size = 10\n",
    "        \n",
    "#         for wi in range(10):\n",
    "# #             if(wi%10000==0):\n",
    "# # #                 clear_output(,wait=True)\n",
    "# # #                 display('Iteration '+str(i)+' Score: '+str(uniform(0, 1)))\n",
    "# #                 print(wi)\n",
    "# #             print(word)\n",
    "#             tries_left = np.zeros(block_size)+6\n",
    "#             guesses = np.zeros((block_size,26))\n",
    "#             valid_guesses = np.array([getValidGuesses(word,guesses) for word in words_by_length[word_length][prev_start_index+block_size*wi: prev_start_index+block_size*(wi+1)]])\n",
    "#             while(tries_left!=0 and sum(valid_guesses)!=0):\n",
    "#                 encoded = encodeWord(word, guesses).reshape(1,-1)\n",
    "#                 predicted = models_all[word_length].predict([encoded])\n",
    "\n",
    "#                 models_all[word_length].fit(encoded,valid_guesses.reshape(1,-1), verbose=False)\n",
    "\n",
    "#     #             print(guesses)\n",
    "\n",
    "#                 predicted[0][(guesses!=0)] = 0\n",
    "#                 new_guess = np.argmax(predicted)\n",
    "\n",
    "#                 guesses[new_guess] = 1\n",
    "\n",
    "#                 if(valid_guesses[new_guess]>0):\n",
    "#                     valid_guesses = getValidGuesses(word, guesses)\n",
    "#                 else:\n",
    "#                     tries_left-=1\n",
    "\n",
    "#             if(tries_left==0):\n",
    "#                 losses += 1\n",
    "# #                 print('valid guesses left:',np.where(valid_guesses!=0),[chr(ord('a')+i) for i in np.where(valid_guesses!=0)[0]])\n",
    "# #                 print('tries_left: ',tries_left)\n",
    "#             else:\n",
    "#                 wins += 1\n",
    "# #                 print('tries_left: ',tries_left)\n",
    "#         prev_start_index += block_size\n",
    "#         print('wins: ',wins,\"and losses:\",losses)\n",
    "# #                 print('guessed:',chr(ord('a')+new_guess)+\" and tried_left:\",tries_left)\n",
    "# #                 print('valid guesses left:',[chr(ord('a')+i) for (i,x) in enumerate(valid_guesses)  if x>0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 17\n",
      "2 264\n",
      "3 2201\n",
      "4 5287\n",
      "5 11274\n",
      "6 19541\n",
      "7 25948\n",
      "8 30452\n",
      "9 30906\n",
      "10 26953\n",
      "11 22786\n",
      "12 18178\n",
      "13 12956\n",
      "14 8710\n",
      "15 5211\n",
      "16 3143\n",
      "17 1775\n",
      "18 859\n",
      "19 441\n",
      "20 225\n",
      "21 98\n",
      "22 44\n",
      "23 14\n",
      "24 9\n",
      "25 3\n",
      "27 2\n",
      "28 1\n",
      "29 2\n"
     ]
    }
   ],
   "source": [
    "for i in sorted(words_by_length.keys()):\n",
    "    print(i,len(words_by_length[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "########testing###########\n",
    "def getAccuracy(word_length):\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    for word in test_set5[:1000]:\n",
    "        tries_left = 6\n",
    "        guesses = np.zeros(26)\n",
    "        valid_guesses = getValidGuesses(word,guesses)\n",
    "        while(tries_left!=0 and sum(valid_guesses)!=0):\n",
    "            encoded = encodeWord(word, guesses).reshape(1,-1)\n",
    "            predicted = models_all[word_length].predict([encoded])\n",
    "\n",
    "    #         models_all[word_length].fit(encoded,valid_guesses.reshape(1,-1), verbose=False)\n",
    "    # \n",
    "    #             print(guesses)\n",
    "\n",
    "            predicted[0][(guesses!=0)] = 0\n",
    "            new_guess = np.argmax(predicted)\n",
    "\n",
    "            guesses[new_guess] = 1\n",
    "\n",
    "            if(valid_guesses[new_guess]>0):\n",
    "                valid_guesses = getValidGuesses(word, guesses)\n",
    "            else:\n",
    "                tries_left-=1\n",
    "\n",
    "        if(tries_left==0):\n",
    "            losses += 1\n",
    "    #                 print('valid guesses left:',np.where(valid_guesses!=0),[chr(ord('a')+i) for i in np.where(valid_guesses!=0)[0]])\n",
    "    #                 print('tries_left: ',tries_left)\n",
    "        else:\n",
    "            wins += 1\n",
    "\n",
    "    print('wins: ',wins,\"and losses:\",losses)\n",
    "    return wins/(wins+losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins:  117 and losses: 883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.117"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccuracy(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples\n",
      "10/10 [==============================] - 0s 8ms/sample - loss: 0.3638 - mean_squared_error: 0.3638\n",
      "Train on 10 samples\n",
      "10/10 [==============================] - 0s 669us/sample - loss: 0.3547 - mean_squared_error: 0.3547\n",
      "Train on 10 samples\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 0.3309 - mean_squared_error: 0.3309\n",
      "Train on 10 samples\n",
      "10/10 [==============================] - 0s 1ms/sample - loss: 0.3511 - mean_squared_error: 0.3511\n",
      "Train on 10 samples\n",
      "10/10 [==============================] - 0s 952us/sample - loss: 0.3035 - mean_squared_error: 0.3035\n",
      "Train on 10 samples\n",
      "10/10 [==============================] - 0s 547us/sample - loss: 0.3353 - mean_squared_error: 0.3353\n",
      "Train on 10 samples\n",
      "10/10 [==============================] - 0s 504us/sample - loss: 0.3059 - mean_squared_error: 0.3059\n",
      "Train on 10 samples\n",
      "10/10 [==============================] - 0s 457us/sample - loss: 0.3078 - mean_squared_error: 0.3078\n",
      "Train on 10 samples\n",
      "10/10 [==============================] - 0s 899us/sample - loss: 0.3406 - mean_squared_error: 0.3406\n",
      "Train on 10 samples\n",
      "10/10 [==============================] - 0s 377us/sample - loss: 0.2797 - mean_squared_error: 0.2797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    model.fit(np.random.rand(10,30), np.random.rand(10,26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
